{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b42dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.data.transforms import video\n",
    "from gluoncv import utils\n",
    "from gluoncv.model_zoo import get_model\n",
    "\n",
    "import time\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils import try_import_cv2\n",
    "cv2 = try_import_cv2()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9dc69",
   "metadata": {},
   "source": [
    "#### For real time implementation on webcam requires some code changes to capture the video in 32 frames and passed it for inferencing. Use cv2.putText to place the predicted action on the video. However there will be a video lag playback depending on the GPU and inferencing speed. Due to a lack of decent GPU to perform real time inferencing. The real time inferencing is not implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f322dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code for real time webcam but not implemented.\n",
    "\n",
    "# clip_input = []\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# num_frames = 32\n",
    "\n",
    "# for i in range(num_frames):\n",
    "#     ret, frame = cap.read()\n",
    "#     cv2.imshow('frame', frame)\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     clip_input.append(frame)\n",
    "    \n",
    "# # After the loop release the cap object\n",
    "# cap.release()\n",
    "# # Destroy all the windows\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd2e57",
   "metadata": {},
   "source": [
    "### Use webcam to capture a sample video of me drinking to do the inferencing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e477da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "time.sleep(1)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,  480))\n",
    "\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = vid.read()\n",
    "  \n",
    "    # Display the resulting frame\n",
    "    \n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "      \n",
    "    # the 'q' button is set as the\n",
    "    # quitting button you may use any\n",
    "    # desired button of your choice\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "vid.release()\n",
    "out.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb9bb7",
   "metadata": {},
   "source": [
    "### Extract the 16 frames from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5cc5cb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluoncv.utils.filesystem import try_import_decord\n",
    "decord = try_import_decord()\n",
    "\n",
    "vr = decord.VideoReader('output.avi')\n",
    "frame_id_list = range(0, 64, 2)\n",
    "video_data = vr.get_batch(frame_id_list).asnumpy()\n",
    "clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da15e45",
   "metadata": {},
   "source": [
    "### Reszie the clips to 224x224 and stacked and reshaped for model input requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "09b3381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_fn = video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "clip_input = transform_fn(clip_input)\n",
    "clip_input = np.stack(clip_input, axis=0)\n",
    "clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n",
    "clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bd05a",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "15e97de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\lizar/.mxnet/models\\i3d_resnet50_v1_kinetics400-568a722e.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 208483/208483 [00:24<00:00, 8379.80KB/s]\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'i3d_inceptionv1_kinetics400'\n",
    "model_name = 'i3d_resnet50_v1_kinetics400'\n",
    "net = get_model(model_name, nclass=400, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "356ba10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input video clip is classified to be\n",
      "\t[drinking], with probability 0.851.\n",
      "\t[drinking_beer], with probability 0.148.\n",
      "\t[drinking_shots], with probability 0.001.\n",
      "\t[tasting_beer], with probability 0.001.\n",
      "\t[gargling], with probability 0.000.\n"
     ]
    }
   ],
   "source": [
    "pred = net(nd.array(clip_input))\n",
    "\n",
    "classes = net.classes\n",
    "topK = 5\n",
    "ind = nd.topk(pred, k=topK)[0].astype('int')\n",
    "print('The input video clip is classified to be')\n",
    "for i in range(topK):\n",
    "    print('\\t[%s], with probability %.3f.'%\n",
    "          (classes[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2bc73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
